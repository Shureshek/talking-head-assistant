{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86adbd28-80a7-4439-8f50-d986fbbfefaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoX could not be found!\n",
      "\n",
      "    If you do not have SoX, proceed here:\n",
      "     - - - http://sox.sourceforge.net/ - - -\n",
      "\n",
      "    If you do (or think that you should) have SoX, double-check your\n",
      "    path variables.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import sounddevice as sd\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1932fc86-da38-4ef0-a29f-18cfdb293004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4090\n",
      "flash_attn установлен успешно\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "from flash_attn import flash_attn_func  # или flash_attn_qkvpacked_func и т.д.\n",
    "print(\"flash_attn установлен успешно\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0191d53f-4cb9-4d03-8f56-21f7b44199e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.asr.whisper_asr import WhisperTranscriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331f82cf-4ef9-48d3-8c47-3fcce0adf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.voice_clone.clone_manager import VoiceCloneManager\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb836a6c-e9f8-4f18-8e50-250635a54295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры записи\n",
    "SAMPLE_RATE = 16000  # Гц\n",
    "DURATION_MAX = 60    # макс. время записи в секундах\n",
    "AUDIO_QUEUE = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79fb766d-c05a-4fcb-ae3a-0c74212d411d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71afa0687b074e459048386394382d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tts_model = Qwen3TTSModel.from_pretrained(\n",
    "    \"Qwen/Qwen3-TTS-12Hz-0.6B-Base\",\n",
    "    device_map=\"cuda:0\",\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a922627-7f87-47c7-8b94-460950690704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback для записи аудио в очередь\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(f\"Запись: {status}\")\n",
    "    AUDIO_QUEUE.put(bytes(indata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b910e5d-cc11-4ab1-b39c-35f06f219d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция записи аудио в отдельном потоке\n",
    "def record_audio(stop_event: threading.Event):\n",
    "    with sd.RawInputStream(\n",
    "        samplerate=16000,\n",
    "        blocksize=1600,\n",
    "        dtype='int16',\n",
    "        channels=1,\n",
    "        callback=audio_callback\n",
    "    ):\n",
    "        # Ждём пока не установлен флаг остановки\n",
    "        while not stop_event.is_set():\n",
    "            sd.sleep(100)  # проверяем флаг каждые 100 мс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f0e464-a157-42e9-acb0-97238ec54178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Говори, нажми Enter для остановки\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запись завершена.\n"
     ]
    }
   ],
   "source": [
    "# 1. Запуск потока записи\n",
    "stop_event = threading.Event()\n",
    "record_thread = threading.Thread(target=record_audio, args=(stop_event,))\n",
    "record_thread.start()\n",
    "\n",
    "input(\"Говори, нажми Enter для остановки\\n\")\n",
    "stop_event.set()\n",
    "record_thread.join()\n",
    "print(\"Запись завершена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb02c22-df22-4dde-92f0-537269b11325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем записанные блоки в один numpy-массив\n",
    "audio_data_bytes = b\"\".join(list(AUDIO_QUEUE.queue))\n",
    "if len(audio_data_bytes) == 0:\n",
    "    print(\"Не было записано ни одного блока аудио.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84900cc0-8a49-4d82-84e5-468fb6e021e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертируем в numpy array float32 в диапазоне [-1,1]\n",
    "audio_int16 = np.frombuffer(audio_data_bytes, dtype=np.int16)\n",
    "audio_np = audio_int16.astype(np.float32) / 32768.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c731141-ee33-4704-ae32-0d1a21ccefc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распознанный текст: \" Ненавижу детей, ненавижу этих маленьких ёбаных чертей.\"\n"
     ]
    }
   ],
   "source": [
    "# 2. Распознавание речи (Whisper)\n",
    "transcriber = WhisperTranscriber()  # или другая модель Whisper\n",
    "text, info = transcriber.transcribe(audio_np)\n",
    "\n",
    "print(f\"Распознанный текст: \\\"{text}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c51aa47-e3a3-4def-a24f-cdae931654f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ты сказал:  Ненавижу детей, ненавижу этих маленьких ёбаных чертей.\n"
     ]
    }
   ],
   "source": [
    "# 3. Генерация ответа (заглушка)\n",
    "response_text = f\"Ты сказал: {text}\"\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c68ce9e7-4f4c-472f-9192-09b1dc95c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clone_path: voices\\Julia.pkl\n"
     ]
    }
   ],
   "source": [
    "# Инициализация менеджера\n",
    "manager = VoiceCloneManager(model=tts_model)\n",
    "\n",
    "# Имя человека для клонирования\n",
    "person_name = \"Julia\"\n",
    "\n",
    "# Получаем или создаем prompt\n",
    "prompt_items = manager.load_or_create_clone(person_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c36d2db-795d-4c77-9a17-4328dc66f5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аудио сохранено: Julia_clone.wav\n"
     ]
    }
   ],
   "source": [
    "# Генерация аудио\n",
    "sentences = response_text\n",
    "languages = \"Russian\"\n",
    "\n",
    "wavs, sr = tts_model.generate_voice_clone(\n",
    "    text=sentences,\n",
    "    language=languages,\n",
    "    voice_clone_prompt=prompt_items,\n",
    ")\n",
    "\n",
    "# Сохраняем первый результат\n",
    "response_wav = (\n",
    "    Path(\"E:/Coding/talking-head-assistant/generated_speech_audio\")\n",
    "    / f\"{person_name}_clone.wav\"\n",
    ")\n",
    "\n",
    "sf.write(response_wav, wavs[0], sr)\n",
    "print(f\"Аудио сохранено: {person_name}_clone.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e7a4698-5d81-47f2-b6fa-15e9c420d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV2LIP_PYTHON = r\"C:\\Users\\Shurik\\anaconda3\\envs\\wav2lip\\python.exe\"\n",
    "WAV2LIP_DIR = Path(r\"E:\\Coding\\talking-head-assistant\\third_party\\Wav2Lip\")\n",
    "RESULT_VIDEO_DIR = Path(r\"E:\\Coding\\talking-head-assistant\\result_video\")\n",
    "\n",
    "stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_video_path = RESULT_VIDEO_DIR / f\"{person_name}_{stamp}.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79cb8f11-dd33-4f14-806c-efd36d489717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запускаем Wav2Lip для синхронизации губ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['C:\\\\Users\\\\Shurik\\\\anaconda3\\\\envs\\\\wav2lip\\\\python.exe', 'inference.py', '--checkpoint_path', 'checkpoints/wav2lip_gan.pth', '--face', 'face_video.mp4', '--audio', 'E:\\\\Coding\\\\talking-head-assistant\\\\generated_speech_audio\\\\Julia_clone.wav', '--outfile', 'E:\\\\Coding\\\\talking-head-assistant\\\\result_video\\\\Julia_20260205_212825.mp4', '--nosmooth'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav2lip_cmd = [\n",
    "    WAV2LIP_PYTHON,\n",
    "    \"inference.py\",\n",
    "    \"--checkpoint_path\", \"checkpoints/wav2lip_gan.pth\",\n",
    "    \"--face\", \"face_video.mp4\",\n",
    "    \"--audio\", str(response_wav),\n",
    "    \"--outfile\", str(result_video_path),\n",
    "    \"--nosmooth\"\n",
    "]\n",
    "print(\"Запускаем Wav2Lip для синхронизации губ...\")\n",
    "subprocess.run(\n",
    "    wav2lip_cmd,\n",
    "    cwd=WAV2LIP_DIR,\n",
    "    check=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd47c882-f69b-4f04-83d4-302dd1dd7ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Воспроизведение видео (нажмите 'q' для выхода)...\n"
     ]
    }
   ],
   "source": [
    "# 6. Воспроизведение полученного видео через OpenCV\n",
    "def play_audio(path):\n",
    "    data, sr = sf.read(path)\n",
    "    sd.play(data, sr)\n",
    "    sd.wait()\n",
    "\n",
    "audio_thread = threading.Thread(\n",
    "    target=play_audio,\n",
    "    args=(response_wav,),\n",
    "    daemon=True\n",
    ")\n",
    "audio_thread.start()\n",
    "\n",
    "cap = cv2.VideoCapture(str(result_video_path))\n",
    "if not cap.isOpened():\n",
    "    print(\"Ошибка: не удалось открыть видео result_video.mp4.\")\n",
    "print(\"Воспроизведение видео (нажмите 'q' для выхода)...\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Avatar\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f2ff4-b787-43f2-81ae-255034db22b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
